{
  "name": "Deep-compression-alexnet",
  "tagline": "Deep Compression on AlexNet",
  "body": "# Deep Compression on AlexNet\r\nThis is a demo of [Deep Compression](http://arxiv.org/pdf/1510.00149v5.pdf) compressing AlexNet from 233MB to 8.9MB without loss of accuracy. It only differs from the paper that Huffman coding is not applied.\r\n\r\n# Related Papers\r\n[Learning both Weights and Connections for Efficient Neural Network (NIPS'15)](http://arxiv.org/pdf/1506.02626v3.pdf)\r\n\r\n[Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding (ICLR'16, best paper award)](http://arxiv.org/pdf/1510.00149v5.pdf)\r\n\r\n[EIE: Efficient Inference Engine on Compressed Deep Neural Network (ISCA'16)](http://arxiv.org/pdf/1602.01528v1.pdf)\r\n\r\nIf you find Deep Compression useful in your research, please consider citing the paper:\r\n\r\n\t@inproceedings{han2015learning,\r\n\t  title={Learning both Weights and Connections for Efficient Neural Network},\r\n\t  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},\r\n\t  booktitle={Advances in Neural Information Processing Systems (NIPS)},\r\n\t  pages={1135--1143},\r\n\t  year={2015}\r\n\t}\r\n\t\r\n\t\r\n\t@article{han2015deep_compression,\r\n\t  title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},\r\n\t  author={Han, Song and Mao, Huizi and Dally, William J},\r\n\t  journal={International Conference on Learning Representations (ICLR)},\r\n\t  year={2016}\r\n\t}\r\n\t\r\n**A hardware accelerator working directly on the deep compressed model:**\r\n\t\r\n\t@article{han2016eie,\r\n\t  title={EIE: Efficient Inference Engine on Compressed Deep Neural Network},\r\n\t  author={Han, Song and Liu, Xingyu and Mao, Huizi and Pu, Jing and Pedram, Ardavan and Horowitz, Mark A and Dally, William J},\r\n\t  journal={International Conference on Computer Architecture (ISCA)},\r\n\t  year={2016}\r\n\t}\r\n\r\n\r\n\r\n# Usage:\r\n\r\n    export CAFFE_ROOT=$your caffe root$\r\n\r\n    python decode.py bvlc_alexnet_deploy.prototxt AlexNet_compressed.net $CAFFE_ROOT/alexnet.caffemodel \r\n\r\n    cd $CAFFE_ROOT\r\n\r\n    ./build/tools/caffe test --model=models/bvlc_alexnet/train_val.prototxt --weights=alexnet.caffemodel --iterations=1000 --gpu 0\r\n\r\n\r\n# Test Result:\r\n\tI1022 20:18:58.336736 13182 caffe.cpp:198] accuracy_top1 = 0.57074\r\n\tI1022 20:18:58.336745 13182 caffe.cpp:198] accuracy_top5 = 0.80254\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}